### About

Given the ubiquity of Machine Learning (ML) systems and their relevance in daily lives, it is
important to ensure private and safe handling of data alongside equity in human experience.
These are expected by all the stakeholders involved: both regulatory bodies and consumers
alike. This is manifested in the increased interest in one – but not the only – of the facets of
trustworthiness: privacy and fairness research has been gaining immense interest in several
areas of machine learning domains (e.g. computer vision, natural language processing),
including in speech applications. Within this broad realm of Trustworthy ML, approaches such as
differential privacy, continual learning and federated learning aim to either obfuscate customer
data or reduce reliance on data retention. On the other hand, fairness measurement and
enhancement approaches target fairness in the ML systems. There are other facets of
trustworthy ML including robustness, safety, explainability, resilience, and transparency. As a
key human-centered realm, with applications ranging from commerce, law enforcement to
healthcare, speech processing exemplifies these requirements for trustworthiness at many
levels. It presents a unique set of challenges for Trustworthy ML, given the rich information
carried in linguistic and paralinguistic content including speaker trait, interaction and state
characteristics. Further, the relative ease of uncovering protected attributes such as gender,
nationality/accent from the speech signal by an adversary makes it especially important to study
model privacy in speech processing. These topics are essentially interdisciplinary.

Interspeech conference offers the ideal venue for this special session which would invite
submissions focusing on the design and application of emerging techniques for trustworthy
speech processing including but not limited to: (i) differential privacy, (ii) discovery and defense
against emerging privacy attacks, (iii) model interpretability, (iv) continual/incremental/federated
learning and, (v) quantifying & mitigating bias in speech based models. Given the recent
emphasis of these techniques in speech based models, this special session will serve to foster
collaboration across researchers experienced in trustworthy ML, speech as well as new entrants
in this research area. We will also invite submissions from industrial organizations given the
relevance of the topic in their setting.

### Contact
If you have any questions, please contact us at trustworthyspeechprocessing@gmail.com
